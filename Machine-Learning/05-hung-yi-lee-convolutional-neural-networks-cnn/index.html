<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="keywords" content="Hexo Theme Keep"><meta name="description" content="Hexo Theme Keep"><meta name="author" content="Carpe Tu"><title>05_Hung-yi Lee_Convolutional Neural Networks(CNN) | Carpe&#39;s Blog</title><link rel="stylesheet" href="/css/style.css"><link rel="shortcut icon" href="https://pic.imgdb.cn/item/622b2b2e5baa1a80abf6fcff.png"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/fontawesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/regular.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/solid.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/brands.min.css"><script id="hexo-configurations">let KEEP=window.KEEP||{};KEEP.hexo_config={hostname:"overduse.github.io",root:"/",language:"en",path:"search.json"},KEEP.theme_config={toc:{enable:!0,number:!0,expand_all:!0,init_open:!0},style:{primary_color:"#0066cc",logo:"https://pic.imgdb.cn/item/622b2b2e5baa1a80abf6fcff.png",favicon:"https://pic.imgdb.cn/item/622b2b2e5baa1a80abf6fcff.png",avatar:"https://pic.imgdb.cn/item/639ece3eb1fccdcd365542dd.jpg",font_size:"15.6px",font_family:null,hover:{shadow:!0,scale:!0},first_screen:{enable:!0,header_transparent:!0,background_img:"/images/bg.svg",description:"Keep writing and Keep loving.",font_color:null,hitokoto:!0},scroll:{progress_bar:!0,percent:!0}},local_search:{enable:!0,preload:!0},code_copy:{},code_block:{tools:{enable:!0,style:"mac"},highlight_theme:"default"},side_tools:{},pjax:{enable:!0},lazyload:{enable:!0},comment:{enable:!1,use:"valine",valine:{appid:null,appkey:null,placeholder:null},gitalk:{github_id:null,github_admins:null,repository:null,client_id:null,client_secret:null},twikoo:{env_id:null,region:null,version:"1.6.7"},waline:{server_url:null,reaction:!1,version:2}},post:{author_label:{enable:!0,auto:!1,custom_label_list:["Bell","Red Whistle","Blue Whistle","Moon Whistle","Black Whistle","YouWorth"]},word_count:{enable:!0,wordcount:!0,min2read:!0},img_align:"center",copyright_info:!0},version:"3.6.1"},KEEP.language_ago={second:"%s seconds ago",minute:"%s minutes ago",hour:"%s hours ago",day:"%s days ago",week:"%s weeks ago",month:"%s months ago",year:"%s years ago"},KEEP.language_code_block={copy:"Copy code",copied:"Copied",fold:"Fold code block",folded:"Folded"},KEEP.language_copy_copyright={copy:"Copy copyright info",copied:"Copied",title:"Original article title",author:"Original article author",link:"Original article link"}</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Keep Theme" type="application/atom+xml">
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div class="progress-bar-container"><span class="scroll-progress-bar"></span> <span class="pjax-progress-bar"></span> <i class="pjax-progress-icon fas fa-circle-notch fa-spin"></i></div><main class="page-container"><div class="page-main-content"><div class="page-main-content-top"><header class="header-wrapper"><div class="header-content"><div class="left"><a class="logo-image" href="/"><img src="https://pic.imgdb.cn/item/622b2b2e5baa1a80abf6fcff.png"> </a><a class="logo-title" href="/">Carpe&#39;s Blog</a></div><div class="right"><div class="pc"><ul class="menu-list"><li class="menu-item"><a href="/">HOME</a></li><li class="menu-item"><a href="/archives">ARCHIVES</a></li><li class="menu-item"><a href="/categories">CATEGORIES</a></li><li class="menu-item"><a href="/tags">TAGS</a></li><li class="menu-item"><a href="/links">LINKS</a></li><li class="menu-item"><a href="/about">ABOUT</a></li><li class="menu-item"><a href="/changelog">CHANGELOG</a></li><li class="menu-item search search-popup-trigger"><i class="fas fa-search"></i></li></ul></div><div class="mobile"><div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div><div class="icon-item menu-bar"><div class="menu-bar-middle"></div></div></div></div></div><div class="header-drawer"><ul class="drawer-menu-list"><li class="drawer-menu-item flex-center"><a href="/">HOME</a></li><li class="drawer-menu-item flex-center"><a href="/archives">ARCHIVES</a></li><li class="drawer-menu-item flex-center"><a href="/categories">CATEGORIES</a></li><li class="drawer-menu-item flex-center"><a href="/tags">TAGS</a></li><li class="drawer-menu-item flex-center"><a href="/links">LINKS</a></li><li class="drawer-menu-item flex-center"><a href="/about">ABOUT</a></li><li class="drawer-menu-item flex-center"><a href="/changelog">CHANGELOG</a></li></ul></div><div class="window-mask"></div></header></div><div class="page-main-content-middle"><div class="main-content"><div class="fade-in-down-animation"><div class="post-page-container"><div class="article-content-container"><div class="article-title"><span class="title-hover-animation">05_Hung-yi Lee_Convolutional Neural Networks(CNN)</span></div><div class="article-header"><div class="avatar"><img src="https://pic.imgdb.cn/item/639ece3eb1fccdcd365542dd.jpg"></div><div class="info"><div class="author"><span class="name">Carpe Tu</span> <span class="author-label">Black Whistle</span></div><div class="meta-info"><div class="article-meta-info"><span class="article-date article-meta-item"><i class="fa-regular fa-calendar-plus"></i>&nbsp; <span class="pc">2022-04-05 12:53:29</span> <span class="mobile">2022-04-05 12:53</span> </span><span class="article-update-date article-meta-item"><i class="fas fa-file-pen"></i>&nbsp; <span class="pc">2022-12-12 11:06:57</span> </span><span class="article-categories article-meta-item"><i class="fas fa-folder"></i>&nbsp;<ul><li><a href="/categories/Machine-Learning/">Machine Learning</a>&nbsp;</li></ul></span><span class="article-tags article-meta-item"><i class="fas fa-tags"></i>&nbsp;<ul><li><a href="/tags/Courses-Notes/">Courses Notes</a>&nbsp;</li><li>| <a href="/tags/Neural-Network/">Neural Network</a>&nbsp;</li><li>| <a href="/tags/Classification/">Classification</a>&nbsp;</li><li>| <a href="/tags/Hung-yi-Lee/">Hung-yi Lee</a>&nbsp;</li><li>| <a href="/tags/CNN/">CNN</a>&nbsp;</li></ul></span><span class="article-wordcount article-meta-item"><i class="fas fa-file-word"></i>&nbsp;<span>1.1k Words</span> </span><span class="article-min2read article-meta-item"><i class="fas fa-clock"></i>&nbsp;<span>5 Mins</span> </span><span class="article-pv article-meta-item"><i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span></span></div></div></div></div><div class="article-content keep-markdown-body"><h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><p>一种常用的神经网络框架，被用于 <strong>图像识别</strong>，影像辨识。</p><h1 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h1><h2 id="图形预处理"><a href="#图形预处理" class="headerlink" title="图形预处理"></a>图形预处理</h2><ul><li>图像识别系统 处理的问题一般会有不同的scale，一般的做法是：<br>将输入的，要处理的图像，～rescale～<strong>resize</strong>为统一的、要处理的图像大小。<br><em>All the images to be classified have the same size.</em></li><li>Output 和 Label： one-hot vector</li><li>Criterion： <strong>Cross-entropy</strong></li></ul><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624bdf95239250f7c5394b6e.jpg"></p><h2 id="图像数据组织"><a href="#图像数据组织" class="headerlink" title="图像数据组织"></a>图像数据组织</h2><p>一般图像数据会被表示为（high<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:.02ex" xmlns="http://www.w3.org/2000/svg" width="1.76ex" height="1.09ex" role="img" focusable="false" viewBox="0 -491 778 482"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g></g></g></svg></mjx-container>width<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:.02ex" xmlns="http://www.w3.org/2000/svg" width="1.76ex" height="1.09ex" role="img" focusable="false" viewBox="0 -491 778 482"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g></g></g></svg></mjx-container>channels)</p><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624be290239250f7c53f4fd2.jpg"></p><h2 id="Observation"><a href="#Observation" class="headerlink" title="Observation"></a>Observation</h2><ol><li>we needn’t identify the full picture.<blockquote><p>We just need identify some critical patterns.Some patterns are much smaller than the whole image.</p></blockquote></li><li>Some patterns appear in different regions</li><li>Subsampling the pixels will not change the object(下采样不会改变图像表征的物体)</li></ol><h2 id="Simplification"><a href="#Simplification" class="headerlink" title="Simplification"></a>Simplification</h2><h3 id="Receptive-field"><a href="#Receptive-field" class="headerlink" title="Receptive field"></a>Receptive field</h3><p>感受野，是一个定义 Neuron（“神经元”） 感知范围的一个概念。每个神经元只感受自己的感受野的内容。</p><ul><li>一些精心设计的 Neural Network 会有 Cover only some channels 的设计（这种情况特殊处理，只有pattern出现在某些channel的情况下）</li><li>最经典的 Receptive field 的安排：会看全部channel</li><li>cover all the channels 后，会感受野只剩下两个参数，high&amp;width，这俩属性共同决定： <strong>kernel size</strong></li><li>一般一个 receptive field 会有一组 Neuron 来感知。</li></ul><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624bff09239250f7c57978c9.jpg"></p><p>这里的几个定义的参数，其实也就是conv()函数的传入参数。</p><ol><li>kernel size、stride 会影响生成“图像”的纬度</li><li>padding 关乎越界情况下的填充处理，只会影响生成的值</li></ol><h3 id="parameter-sharing"><a href="#parameter-sharing" class="headerlink" title="parameter sharing"></a>parameter sharing</h3><p>不同位置，同样pattern的感知使用的参数不同。两个 Neuron 相同。</p><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624c025a239250f7c580aa04.jpg"></p><p>Two Neurons with the same receptive field has a set of neurons</p><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624cdc78239250f7c5c86d9e.jpg"></p><ul><li>Each receptive field has a set of neurons (e.g., 64 neurons)</li><li>Each receptive field has the neurons with the same set of parameters</li></ul><h3 id="Pooling（池化"><a href="#Pooling（池化" class="headerlink" title="Pooling（池化"></a>Pooling（池化</h3><p>解决图像的缩放的感知问题</p><h4 id="Max-Pooling"><a href="#Max-Pooling" class="headerlink" title="Max Pooling"></a>Max Pooling</h4><p>下采样过程中，感受野里选最大的</p><h4 id="Mean-Pooling"><a href="#Mean-Pooling" class="headerlink" title="Mean Pooling"></a>Mean Pooling</h4><p>选均值</p><h3 id="Convolutional-Layers-Poooling"><a href="#Convolutional-Layers-Poooling" class="headerlink" title="Convolutional Layers + Poooling"></a>Convolutional Layers + Poooling</h3><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624ce1d3239250f7c5cea0d4.jpg"></p><p>实践中，我们常常在 <strong>卷积层</strong> 后跟上一层 pooling，Pooling 做的事情就是把图片变小。</p><p>近两年的论文设计中，很多模型都抛弃了 Pooling（运算资源够多，支撑不做 pooling</p><p>但是在近期，图像识别的论文中，出现了大量 Full-convolution 的网络。</p><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624ce2ad239250f7c5cf9d77.jpg"><br><em>常见CNN</em></p><h1 id="Benefit-of-Convolutional-Layer"><a href="#Benefit-of-Convolutional-Layer" class="headerlink" title="Benefit of Convolutional Layer"></a>Benefit of Convolutional Layer</h1><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624cdddc239250f7c5ca0f1d.jpg"></p><ul><li>some patterns are much smaller than the whole image.</li><li>the same patterns appear in diff regions</li></ul><h1 id="from-Filter"><a href="#from-Filter" class="headerlink" title="from Filter"></a>from Filter</h1><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624cde8b239250f7c5cade62.jpg"></p><ol><li>The values in the filters are unknown parameters.</li><li>the output of the filters are called <strong>Feature Map</strong></li></ol><h2 id="Mutiple-Convolutional-Layers"><a href="#Mutiple-Convolutional-Layers" class="headerlink" title="Mutiple Convolutional Layers"></a>Mutiple Convolutional Layers</h2><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624ce01a239250f7c5ccb3ef.jpg"></p><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624ce04e239250f7c5ccf132.jpg"></p><h2 id="the-2-version-introduction"><a href="#the-2-version-introduction" class="headerlink" title="the 2 version introduction"></a>the 2 version introduction</h2><table><thead><tr><th>Neron Version</th><th>Filter Version</th></tr></thead><tbody><tr><td>Each neuron only considers a receptive field</td><td>There are a set of filters detecting small patterns</td></tr><tr><td>The neurons with different receptive fields share the parameters.</td><td>Each filter convolves over the input image.</td></tr></tbody></table><p>They are same story.</p><h1 id="Application"><a href="#Application" class="headerlink" title="Application:"></a>Application:</h1><h2 id="Alpha-Go"><a href="#Alpha-Go" class="headerlink" title="Alpha Go"></a>Alpha Go</h2><p>把棋盘当成图片</p><h3 id="similarity-between-Go-playing-and-Image"><a href="#similarity-between-Go-playing-and-Image" class="headerlink" title="similarity between Go playing and Image"></a>similarity between Go playing and Image</h3><ul><li><p>Some patterns are much smaller than the whole image</p></li><li><p>The same patterns appear in different regions</p></li></ul><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624ce353239250f7c5d06ffa.jpg"></p><p>是否使用 Pooling 还得看 <strong>问题的性质是否适合池化</strong>，下围棋不可能下采样</p><h3 id="More-Applications"><a href="#More-Applications" class="headerlink" title="More Applications"></a>More Applications</h3><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/624ce401239250f7c5d13723.jpg"></p><h1 id="HW3-Image-Classification"><a href="#HW3-Image-Classification" class="headerlink" title="HW3: Image Classification"></a>HW3: Image Classification</h1><h2 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h2><ol><li>Solve image classification with <strong>convolutional neural networks</strong>.</li><li>Improve the performance with <strong>data augmentations</strong>.</li><li>Understand popular image model techniques such as <strong>residual</strong>.</li></ol><h2 id="Tricks"><a href="#Tricks" class="headerlink" title="Tricks"></a>Tricks</h2><h3 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h3><ul><li>visit <a class="link" target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/models.html">torchvision.models<i class="fas fa-external-link-alt"></i></a> for a list of model structures, or go to <a class="link" target="_blank" rel="noopener" href="https://github.com/rwightman/pytorch-image-models">timm<i class="fas fa-external-link-alt"></i></a></li><li>If <strong>Pretrained weights</strong> are not allowed, specially set <strong>pretrained = False</strong></li></ul><h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><ul><li>Modify the image data so non-identical inputs are given to the model each epoch, to prevent overfitting of the model</li><li>Vist <a class="link" target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html">torchvision.transforms<i class="fas fa-external-link-alt"></i></a> for a list of choices and their corresponding effect. Diversity is encouraged! Usually, stacking multiple transformations leads to better results.</li><li>Coding: fill in <em>train_tfm</em> to gain this effect</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Normally, We don't need augmentations in testing and validation.</span></span><br><span class="line"><span class="comment"># All we need here is to resize the PIL image and transform it into Tensor.</span></span><br><span class="line">test_tfm = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># However, it is also possible to use augmentation in the testing phase.</span></span><br><span class="line"><span class="comment"># You may use train_tfm to produce a variety of images and then test using ensemble methods</span></span><br><span class="line">train_tfm = transforms.Compose([</span><br><span class="line">    <span class="comment"># Resize the image into a fixed shape (height = width = 128)</span></span><br><span class="line">    transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">    <span class="comment"># You may add some transforms here.</span></span><br><span class="line">    <span class="comment"># ToTensor() should be the last one of the transforms.</span></span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h4 id="Advanced-Data-Augmentation"><a href="#Advanced-Data-Augmentation" class="headerlink" title="Advanced Data Augmentation"></a>Advanced Data Augmentation</h4><p><u><strong><a class="link" target="_blank" rel="noopener" href="https://arxiv.org/pdf/1710.09412.pdf">mixup<i class="fas fa-external-link-alt"></i></a></strong></u></p><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/62539b55239250f7c51c240f.jpg"></p><p>Coding:</p><ul><li>In your <em>torch.utils.Dataset</em>, <strong>getitem</strong>() needs to return an image that is the linear combination of two images/</li><li>In your <em>torch.utils.Dataset</em>, <strong>getitem</strong>() needs to return a label that is a vector, to assign probabilities to each class.</li><li>You need to explicitly code out the math formula of the cross entropy loss, as <em><strong>CrossEntropyLoss</strong></em> does not support multiple labels.</li></ul><h4 id="Test-Time-Augmentation"><a href="#Test-Time-Augmentation" class="headerlink" title="Test Time Augmentation"></a>Test Time Augmentation</h4><ul><li>The sample code tests images using a deterministic “test transformation”</li><li>You may using the train transformation for a more diversified representation of the images, and predict with multiple variants of the test images.</li><li>Coding: You need to fill in <em>train_tfm</em>, change the augmentation method for test_dataset, and modify prediction code to gain this effect.</li></ul><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/62539e3a239250f7c520a1cc.jpg"></p><ul><li>Usually, test_tfm will produce images that are more identifiable, so you can assign a larger weight to test_tfm results for better performance.</li></ul><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/62539ea4239250f7c5213ecb.jpg"></p><ul><li>Ex: Final Prediction = avg_trian_tfm_pred * <strong>0.5</strong> + test_tfm_pred* <strong>0.5</strong></li></ul><h3 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross Validation"></a>Cross Validation</h3><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/62539f00239250f7c521bd39.jpg"></p><ul><li>Cross-validation is a resampling method that uses diff portions of the data to validate and train a model on different iterations. Ensembling multiple results lead to better performance.</li><li>Coding: You need to merge the current train and validation paths, and resample from those to form new train and validation sets.</li></ul></div><div class="post-copyright-info"><div class="article-copyright-info-container"><ul class="copyright-info-content"><li class="post-title"><span class="type">Post title</span>: <span class="content">05_Hung-yi Lee_Convolutional Neural Networks(CNN)</span></li><li class="post-author"><span class="type">Post author</span>: <span class="content">Carpe Tu</span></li><li class="post-time"><span class="type">Create time</span>: <span class="content">2022-04-05 12:53:29</span></li><li class="post-link"><span class="type">Post link</span>: <span class="content">Machine-Learning/05-hung-yi-lee-convolutional-neural-networks-cnn/</span></li><li class="post-license"><span class="type">Copyright notice</span>: <span class="content">All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.</span></li></ul><div class="copy-copyright-info flex-center tooltip" data-content="Copy copyright info" data-offset-y="-2px"><i class="fa-solid fa-copy"></i></div></div></div><ul class="post-tags-box"><li class="tag-item"><a href="/tags/Courses-Notes/">#Courses Notes</a>&nbsp;</li><li class="tag-item"><a href="/tags/Neural-Network/">#Neural Network</a>&nbsp;</li><li class="tag-item"><a href="/tags/Classification/">#Classification</a>&nbsp;</li><li class="tag-item"><a href="/tags/Hung-yi-Lee/">#Hung-yi Lee</a>&nbsp;</li><li class="tag-item"><a href="/tags/CNN/">#CNN</a>&nbsp;</li></ul><div class="article-nav"><div class="article-prev"><a class="prev" rel="prev" href="/Machine-Learning/06-hung-yi-lee-why-deep-learning/"><span class="left arrow-icon flex-center"><i class="fas fa-chevron-left"></i> </span><span class="title flex-center"><span class="post-nav-title-item">06_Hung-yi Lee_why deep learning?</span> <span class="post-nav-item">Prev posts</span></span></a></div><div class="article-next"><a class="next" rel="next" href="/Tutorial/python-tutorial/"><span class="title flex-center"><span class="post-nav-title-item">Python_tutorial</span> <span class="post-nav-item">Next posts</span> </span><span class="right arrow-icon flex-center"><i class="fas fa-chevron-right"></i></span></a></div></div></div><div class="toc-content-container"><div class="post-toc-wrap"><div class="post-toc"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#CNN"><span class="nav-number">1.</span> <span class="nav-text">CNN</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Image-Classification"><span class="nav-number">2.</span> <span class="nav-text">Image Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E5%BD%A2%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">2.1.</span> <span class="nav-text">图形预处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E7%BB%84%E7%BB%87"><span class="nav-number">2.2.</span> <span class="nav-text">图像数据组织</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Observation"><span class="nav-number">2.3.</span> <span class="nav-text">Observation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Simplification"><span class="nav-number">2.4.</span> <span class="nav-text">Simplification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Receptive-field"><span class="nav-number">2.4.1.</span> <span class="nav-text">Receptive field</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#parameter-sharing"><span class="nav-number">2.4.2.</span> <span class="nav-text">parameter sharing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pooling%EF%BC%88%E6%B1%A0%E5%8C%96"><span class="nav-number">2.4.3.</span> <span class="nav-text">Pooling（池化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Max-Pooling"><span class="nav-number">2.4.3.1.</span> <span class="nav-text">Max Pooling</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mean-Pooling"><span class="nav-number">2.4.3.2.</span> <span class="nav-text">Mean Pooling</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Convolutional-Layers-Poooling"><span class="nav-number">2.4.4.</span> <span class="nav-text">Convolutional Layers + Poooling</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Benefit-of-Convolutional-Layer"><span class="nav-number">3.</span> <span class="nav-text">Benefit of Convolutional Layer</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#from-Filter"><span class="nav-number">4.</span> <span class="nav-text">from Filter</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Mutiple-Convolutional-Layers"><span class="nav-number">4.1.</span> <span class="nav-text">Mutiple Convolutional Layers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#the-2-version-introduction"><span class="nav-number">4.2.</span> <span class="nav-text">the 2 version introduction</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Application"><span class="nav-number">5.</span> <span class="nav-text">Application:</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Alpha-Go"><span class="nav-number">5.1.</span> <span class="nav-text">Alpha Go</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#similarity-between-Go-playing-and-Image"><span class="nav-number">5.1.1.</span> <span class="nav-text">similarity between Go playing and Image</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#More-Applications"><span class="nav-number">5.1.2.</span> <span class="nav-text">More Applications</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HW3-Image-Classification"><span class="nav-number">6.</span> <span class="nav-text">HW3: Image Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Objective"><span class="nav-number">6.1.</span> <span class="nav-text">Objective</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tricks"><span class="nav-number">6.2.</span> <span class="nav-text">Tricks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-Selection"><span class="nav-number">6.2.1.</span> <span class="nav-text">Model Selection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Augmentation"><span class="nav-number">6.2.2.</span> <span class="nav-text">Data Augmentation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Advanced-Data-Augmentation"><span class="nav-number">6.2.2.1.</span> <span class="nav-text">Advanced Data Augmentation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Test-Time-Augmentation"><span class="nav-number">6.2.2.2.</span> <span class="nav-text">Test Time Augmentation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cross-Validation"><span class="nav-number">6.2.3.</span> <span class="nav-text">Cross Validation</span></a></li></ol></li></ol></li></ol></div></div></div></div></div></div></div><div class="page-main-content-bottom"><footer class="footer"><div class="info-container"><div class="copyright-info info-item">&copy; <span>2021</span> - 2023 &nbsp;<i class="fas fa-heart icon-animate"></i> &nbsp;<a href="/">Carpe Tu</a></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="website-count info-item">Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp; Totalview&nbsp;<span id="busuanzi_value_site_pv"></span></div><div class="theme-info info-item">Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.6.1</a></div></div></footer></div></div><div class="post-tools"><div class="post-tools-container"><ul class="tools-list"><li class="tools-item flex-center toggle-show-toc"><i class="fas fa-list"></i></li></ul></div></div><div class="right-bottom-side-tools"><div class="side-tools-container"><ul class="side-tools-list"><li class="tools-item tool-font-adjust-plus flex-center"><i class="fas fa-search-plus"></i></li><li class="tools-item tool-font-adjust-minus flex-center"><i class="fas fa-search-minus"></i></li><li class="tools-item tool-dark-light-toggle flex-center"><i class="fas fa-moon"></i></li><li class="tools-item rss flex-center"><a class="flex-center" href="/atom.xml" target="_blank"><i class="fas fa-rss"></i></a></li><li class="tools-item tool-scroll-to-bottom flex-center"><i class="fas fa-arrow-down"></i></li></ul><ul class="exposed-tools-list"><li class="tools-item tool-toggle-show flex-center"><i class="fas fa-cog fa-spin"></i></li><li class="tools-item tool-scroll-to-top flex-center"><i class="arrow-up fas fa-arrow-up"></i> <span class="percent"></span></li></ul></div></div><div class="zoom-in-image-mask"><img class="zoom-in-image"></div><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-input-field-pre"><i class="fas fa-keyboard"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="Search..." spellcheck="false" type="search" class="search-input"></div><span class="close-popup-btn"><i class="fas fa-times"></i></span></div><div id="search-result"><div id="no-result"><i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></main><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/dark-light-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/local-search.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/code-block.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/lazyload.js"></script><div class="post-scripts pjax"><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/post-helper.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/toc.js"></script></div><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/libs/pjax.min.js"></script><script>window.addEventListener("DOMContentLoaded",()=>{window.pjax=new Pjax({selectors:["head title",".page-container",".pjax"],history:!0,debug:!1,cacheBust:!1,timeout:0,analytics:!1,currentUrlFullReload:!1,scrollRestoration:!1}),document.addEventListener("pjax:send",()=>{KEEP.utils.pjaxProgressBarStart()}),document.addEventListener("pjax:complete",()=>{KEEP.utils.pjaxProgressBarEnd(),window.pjax.executeScripts(document.querySelectorAll("script[data-pjax], .pjax script")),KEEP.refresh()})})</script></body></html>
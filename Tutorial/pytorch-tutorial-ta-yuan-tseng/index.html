<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="keywords" content="Hexo Theme Keep"><meta name="description" content="Hexo Theme Keep"><meta name="author" content="Carpe Tu"><title>PyTorch_Tutorial (TA Yuan Tseng) | Carpe&#39;s Blog</title><link rel="stylesheet" href="/css/style.css"><link rel="shortcut icon" href="https://pic.imgdb.cn/item/622b2b2e5baa1a80abf6fcff.png"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/fontawesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/regular.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/solid.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/brands.min.css"><script id="hexo-configurations">let KEEP=window.KEEP||{};KEEP.hexo_config={hostname:"overduse.github.io",root:"/",language:"en",path:"search.json"},KEEP.theme_config={toc:{enable:!0,number:!0,expand_all:!0,init_open:!0},style:{primary_color:"#0066cc",logo:"https://pic.imgdb.cn/item/622b2b2e5baa1a80abf6fcff.png",favicon:"https://pic.imgdb.cn/item/622b2b2e5baa1a80abf6fcff.png",avatar:"https://pic.imgdb.cn/item/639ece3eb1fccdcd365542dd.jpg",font_size:"15.6px",font_family:null,hover:{shadow:!0,scale:!0},first_screen:{enable:!0,header_transparent:!0,background_img:"/images/bg.svg",description:"Keep writing and Keep loving.",font_color:null,hitokoto:!0},scroll:{progress_bar:!0,percent:!0}},local_search:{enable:!0,preload:!0},code_copy:{},code_block:{tools:{enable:!0,style:"mac"},highlight_theme:"default"},side_tools:{},pjax:{enable:!0},lazyload:{enable:!0},comment:{enable:!1,use:"valine",valine:{appid:null,appkey:null,placeholder:null},gitalk:{github_id:null,github_admins:null,repository:null,client_id:null,client_secret:null},twikoo:{env_id:null,region:null,version:"1.6.7"},waline:{server_url:null,reaction:!1,version:2}},post:{author_label:{enable:!0,auto:!1,custom_label_list:["Bell","Red Whistle","Blue Whistle","Moon Whistle","Black Whistle","YouWorth"]},word_count:{enable:!0,wordcount:!0,min2read:!0},img_align:"center",copyright_info:!0},version:"3.6.1"},KEEP.language_ago={second:"%s seconds ago",minute:"%s minutes ago",hour:"%s hours ago",day:"%s days ago",week:"%s weeks ago",month:"%s months ago",year:"%s years ago"},KEEP.language_code_block={copy:"Copy code",copied:"Copied",fold:"Fold code block",folded:"Folded"},KEEP.language_copy_copyright={copy:"Copy copyright info",copied:"Copied",title:"Original article title",author:"Original article author",link:"Original article link"}</script><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Keep Theme" type="application/atom+xml">
</head><body><div class="progress-bar-container"><span class="scroll-progress-bar"></span> <span class="pjax-progress-bar"></span> <i class="pjax-progress-icon fas fa-circle-notch fa-spin"></i></div><main class="page-container"><div class="page-main-content"><div class="page-main-content-top"><header class="header-wrapper"><div class="header-content"><div class="left"><a class="logo-image" href="/"><img src="https://pic.imgdb.cn/item/622b2b2e5baa1a80abf6fcff.png"> </a><a class="logo-title" href="/">Carpe&#39;s Blog</a></div><div class="right"><div class="pc"><ul class="menu-list"><li class="menu-item"><a href="/">HOME</a></li><li class="menu-item"><a href="/archives">ARCHIVES</a></li><li class="menu-item"><a href="/categories">CATEGORIES</a></li><li class="menu-item"><a href="/tags">TAGS</a></li><li class="menu-item"><a href="/links">LINKS</a></li><li class="menu-item"><a href="/about">ABOUT</a></li><li class="menu-item"><a href="/changelog">CHANGELOG</a></li><li class="menu-item search search-popup-trigger"><i class="fas fa-search"></i></li></ul></div><div class="mobile"><div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div><div class="icon-item menu-bar"><div class="menu-bar-middle"></div></div></div></div></div><div class="header-drawer"><ul class="drawer-menu-list"><li class="drawer-menu-item flex-center"><a href="/">HOME</a></li><li class="drawer-menu-item flex-center"><a href="/archives">ARCHIVES</a></li><li class="drawer-menu-item flex-center"><a href="/categories">CATEGORIES</a></li><li class="drawer-menu-item flex-center"><a href="/tags">TAGS</a></li><li class="drawer-menu-item flex-center"><a href="/links">LINKS</a></li><li class="drawer-menu-item flex-center"><a href="/about">ABOUT</a></li><li class="drawer-menu-item flex-center"><a href="/changelog">CHANGELOG</a></li></ul></div><div class="window-mask"></div></header></div><div class="page-main-content-middle"><div class="main-content"><div class="fade-in-down-animation"><div class="post-page-container"><div class="article-content-container"><div class="article-title"><span class="title-hover-animation">PyTorch_Tutorial (TA Yuan Tseng)</span></div><div class="article-header"><div class="avatar"><img src="https://pic.imgdb.cn/item/639ece3eb1fccdcd365542dd.jpg"></div><div class="info"><div class="author"><span class="name">Carpe Tu</span> <span class="author-label">Black Whistle</span></div><div class="meta-info"><div class="article-meta-info"><span class="article-date article-meta-item"><i class="fa-regular fa-calendar-plus"></i>&nbsp; <span class="pc">2022-03-21 11:33:24</span> <span class="mobile">2022-03-21 11:33</span> </span><span class="article-update-date article-meta-item"><i class="fas fa-file-pen"></i>&nbsp; <span class="pc">2022-12-12 11:06:57</span> </span><span class="article-categories article-meta-item"><i class="fas fa-folder"></i>&nbsp;<ul><li><a href="/categories/Tutorial/">Tutorial</a>&nbsp;</li></ul></span><span class="article-tags article-meta-item"><i class="fas fa-tags"></i>&nbsp;<ul><li><a href="/tags/Hung-yi-Lee/">Hung-yi Lee</a>&nbsp;</li><li>| <a href="/tags/PyTorch/">PyTorch</a>&nbsp;</li></ul></span><span class="article-wordcount article-meta-item"><i class="fas fa-file-word"></i>&nbsp;<span>1.3k Words</span> </span><span class="article-min2read article-meta-item"><i class="fas fa-clock"></i>&nbsp;<span>8 Mins</span> </span><span class="article-pv article-meta-item"><i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span></span></div></div></div></div><div class="article-content keep-markdown-body"><h1 id="Videos-Link"><a href="#Videos-Link" class="headerlink" title="Videos Link"></a>Videos Link</h1><p>PyTorch_Tutorial1 <a class="link" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=85uJ9hSaXig">https://www.youtube.com/watch?v=85uJ9hSaXig<i class="fas fa-external-link-alt"></i></a><br>PyTorch_Tutorial2 <a class="link" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=VbqNn20FoHM">https://www.youtube.com/watch?v=VbqNn20FoHM<i class="fas fa-external-link-alt"></i></a></p><h1 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h1><ul><li>Background: Prerequisites &amp; What is Pytorch?</li><li>Training &amp; Testing Neural Networks in Pytorch</li><li>Dataset &amp; Dataloader</li><li>Tensors</li><li>torch.nn; Models, Loss Functions</li><li>torch.optim: Optimization</li><li>Save/load models</li></ul><h1 id="Tutorial1"><a href="#Tutorial1" class="headerlink" title="Tutorial1"></a>Tutorial1</h1><h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><ul><li>We assume u r already familiar with…</li></ul><ol><li><strong>Python3</strong><br>if-else, loop, function, file IO, class,<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:.43ex" xmlns="http://www.w3.org/2000/svg" width="2.652ex" height="0.271ex" role="img" focusable="false" viewBox="0 -310 1172 120"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="22EF" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250ZM525 250Q525 274 542 292T585 310Q609 310 627 294T646 251Q646 226 629 208T586 190T543 207T525 250ZM972 250Q972 274 989 292T1032 310Q1056 310 1074 294T1093 251Q1093 226 1076 208T1033 190T990 207T972 250Z"></path></g></g></g></svg></mjx-container></li><li><strong>Deep Learning Basics</strong><br>Prof. Lee’s 1st &amp; 2nd lecture videos.</li></ol><p>Some knowledge of <strong>NumPy</strong> will also be useful!</p><h2 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h2><ul><li>An <strong>machine learningframework</strong> in Python</li><li>Two main features:<ul><li>N-dimensional <strong>Tensor</strong> computation(like NumPy) on <strong>GPUS</strong></li><li><strong>Automatic differentiation</strong> for training deep neural networks</li></ul></li></ul><h3 id="Training-Neural-Networks"><a href="#Training-Neural-Networks" class="headerlink" title="Training Neural Networks"></a>Training Neural Networks</h3><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/623806ff27f86abb2a5bcc03.jpg"></p><h3 id="Step1–Load-dataset"><a href="#Step1–Load-dataset" class="headerlink" title="Step1–Load dataset"></a>Step1–Load dataset</h3><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/62380d4527f86abb2a70e23e.jpg"></p><ul><li>Dataset: stores data samples and expected values</li><li>Dataloader: groups data in batches, enables multiprocessing</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = MyDataset(file)</span><br><span class="line">dataloader = DataLoader(**dataset**, batch_size, shuffle=True)</span><br></pre></td></tr></table></figure><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/6238309427f86abb2a10945f.jpg"></p><h4 id="Dataset-amp-Dataloader"><a href="#Dataset-amp-Dataloader" class="headerlink" title="Dataset & Dataloader"></a>Dataset &amp; Dataloader</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, file</span>):</span><br><span class="line">        self.data = ...</span><br><span class="line">    <span class="comment"># Read data &amp; preprocess</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">return</span> self.data[index]</span><br><span class="line">    <span class="comment"># Returns one sample at a time</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line">    <span class="comment"># Returns the size of the dataset</span></span><br></pre></td></tr></table></figure><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><h4 id="Tensor–Shape-of-Tensor"><a href="#Tensor–Shape-of-Tensor" class="headerlink" title="Tensor–Shape of Tensor"></a>Tensor–Shape of Tensor</h4><ul><li>Check with.shape()</li></ul><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/6238312e27f86abb2a12eb9d.jpg"></p><p><strong>Note</strong>: <em>dim</em> in Pytorch == <em>axis</em> in NumPy</p><h4 id="Tensor–Creating-Tensors"><a href="#Tensor–Creating-Tensors" class="headerlink" title="Tensor–Creating Tensors"></a>Tensor–Creating Tensors</h4><ul><li>Directly from data(list or numpy.ndarray)<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([[<span class="number">1</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line">x = torch.from_numpy(np.array([[<span class="number">1</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">1</span>]]))</span><br><span class="line"></span><br><span class="line">Output:</span><br><span class="line">tensor([<span class="number">1.</span>, -<span class="number">1.</span>],</span><br><span class="line">        [-<span class="number">1</span>, <span class="number">1.</span>])</span><br></pre></td></tr></table></figure></li><li>Tensor of constant zeros &amp; ones<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros([<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">x = torch.ones([<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">Output:</span><br><span class="line">tensor([[<span class="number">0.</span>,<span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>,<span class="number">0.</span>]])</span><br><span class="line">tensor([[[<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>],</span><br><span class="line">         [<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>]]])</span><br></pre></td></tr></table></figure></li></ul><h4 id="Tensors–Comon-Operations"><a href="#Tensors–Comon-Operations" class="headerlink" title="Tensors–Comon Operations"></a>Tensors–Comon Operations</h4><p>Common arithmetic func are supported, such as:</p><ul><li>Addition z = x + y</li><li>Subtraction z = x - y</li><li>Power y = x.pow(2)</li><li>Summation y = x.sum()</li><li>Mean y = x.mean()<br><strong>Transpose</strong>: transpose 2 specified dimensions<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.zeros([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = x.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure><strong>Squeeze</strong>: remove the specified dimension with length = 1<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.zeros([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = x.squeeze(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 消除第一纬度</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><strong>Unsqueeze</strong>: expand a new dimension<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.zeros([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = x.unsqueeze(<span class="number">1</span>) <span class="comment"># dim = 1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure></li></ul><p><strong>Cat</strong>: concatenate multiple tensors</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.zeros([<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.zeros([<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = torch.zeros([<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>w = torch.Size([<span class="number">2</span>, <span class="number">6</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/62383c8d27f86abb2a4b9ea4.jpg"></p><h4 id="Tensor–Data-Type"><a href="#Tensor–Data-Type" class="headerlink" title="Tensor–Data Type"></a>Tensor–Data Type</h4><ul><li>Using different data types for model and data will cause errors</li></ul><table><thead><tr><th>Data type</th><th>dtype</th><th>tensor</th></tr></thead><tbody><tr><td>32-bit floating point</td><td>torch.float</td><td>torch.Floattensor</td></tr><tr><td>64-bit integer (signed)</td><td>torch.long</td><td>torch.LongTensor</td></tr></tbody></table><ul><li>Similar attributes &amp; same func</li></ul><table><thead><tr><th>PyTorch</th><th>NumPy</th></tr></thead><tbody><tr><td>x.shape</td><td>x.shape</td></tr><tr><td>x.dtype</td><td>x.dtype</td></tr><tr><td>x.reshape/x.view</td><td>x.reshape</td></tr><tr><td>x.squeeze()</td><td>x.squeeze()</td></tr><tr><td>x.unsqueeze(1)</td><td>np.expand_dims(x,1)</td></tr></tbody></table><h4 id="Tensor–Device"><a href="#Tensor–Device" class="headerlink" title="Tensor–Device"></a>Tensor–Device</h4><ul><li><p>Tensors &amp; modules will be computed with <strong>CPU</strong> by default</p><p>Use.<strong>to()</strong> to move tensors to appropriate devices.</p></li><li><p>CPU<br>x = x.to(‘cpu’)</p></li><li><p>GPU<br>x = x.to(‘cuda’)</p></li></ul><h4 id="Tensors–Device-GPU"><a href="#Tensors–Device-GPU" class="headerlink" title="Tensors–Device(GPU)"></a>Tensors–Device(GPU)</h4><ul><li><p>Check if your computer has NVIDIA GPI</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure></li><li><p>Multiple GPUs: specify ‘cuda:0’, ‘cuda:1’, ‘cuda:2’,…</p></li><li><p>Why use GPUs?</p><ul><li>Parallel computing with more cores for arithmetic calculations</li><li>see <a class="link" target="_blank" rel="noopener" href="https://towardsdatascience.com/what-is-a-gpu-and-do-you-need-one-in-deep-learning-718b9597aa0d">What is a GPU and do you need one in Deep Learning?<i class="fas fa-external-link-alt"></i></a></li></ul></li></ul><h4 id="Tensors–Gradient-Calculation"><a href="#Tensors–Gradient-Calculation" class="headerlink" title="Tensors–Gradient Calculation"></a>Tensors–Gradient Calculation</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor([[<span class="number">1.</span> , <span class="number">0.</span>], [-<span class="number">1.</span>, <span class="number">1.</span>]], requires_grad = <span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = x.<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z.backward()        <span class="comment">## 非常重要，目标函数backward</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.grad</span><br><span class="line">tensor([[<span class="number">2.</span>, <span class="number">0.</span>],</span><br><span class="line">        [-<span class="number">2.</span>, <span class="number">2.</span>]])</span><br></pre></td></tr></table></figure><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/623840b827f86abb2a5f822e.jpg"></p><h3 id="Step2–Build-NN"><a href="#Step2–Build-NN" class="headerlink" title="Step2–Build NN"></a>Step2–Build NN</h3><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/6238415d27f86abb2a61492a.jpg"></p><h4 id="torch-nn–Network-Layers"><a href="#torch-nn–Network-Layers" class="headerlink" title="torch.nn–Network Layers"></a>torch.nn–Network Layers</h4><ul><li>Linear Layer(<strong>Fully-connected</strong> Layer)<br>nn.Linear(in_features, out_features)</li></ul><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/6239533f27f86abb2ad6dafd.jpg"></p><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/6239535f27f86abb2ad7909e.jpg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>layer = torch.nn.Linear(<span class="number">32</span>, <span class="number">64</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>layer.weight.shape</span><br><span class="line">torch.Size([<span class="number">64</span>, <span class="number">32</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>layer.bias.shape</span><br><span class="line">torch.Size([<span class="number">64</span>])</span><br></pre></td></tr></table></figure><h4 id="torch-nn-–-Non-Linear-Activation-Function"><a href="#torch-nn-–-Non-Linear-Activation-Function" class="headerlink" title="torch.nn – Non-Linear Activation Function"></a>torch.nn – Non-Linear Activation Function</h4><ul><li>Sigmoid Activation<br>nn.Sigmoid</li><li>ReLU Activation<br>nn.ReLU</li></ul><h4 id="torch-nn-–-Build-Neural-Network"><a href="#torch-nn-–-Build-Neural-Network" class="headerlink" title="torch.nn – Build Neural Network"></a>torch.nn – Build Neural Network</h4><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/623954bc27f86abb2adedd62.jpg"></p><h3 id="Step3–Loss-Func-amp-Optim"><a href="#Step3–Loss-Func-amp-Optim" class="headerlink" title="Step3–Loss Func & Optim"></a>Step3–Loss Func &amp; Optim</h3><h4 id="torch-nn–Loss-Functions"><a href="#torch-nn–Loss-Functions" class="headerlink" title="torch.nn–Loss Functions"></a>torch.nn–Loss Functions</h4><ul><li>Mean Squared Error(for regression tasks)<br>criterion = nn.MSELoss()</li><li>Cross Entropy(for classification tasks)<br>criterion = nn.CrossEntropyLoss()</li><li>loss = criterion(model_out, expected_value)</li></ul><h4 id="torch-optim"><a href="#torch-optim" class="headerlink" title="torch.optim"></a>torch.optim</h4><ul><li><p>Gradient based <strong>optimization algorithms</strong> that adjust network<br>parameters to reduce error.</p></li><li><p>E.g. Stochastic Gradient Descent(SGD)<br>torch.optim.SGD(model.parameters(), lr, momentum = 0)</p></li></ul><p>optimizer = torch.optim.SGD(model.parameters(), lr, momentum = 0)</p><ul><li>For every batch of data:<ol><li>Call optimizer.zero_grad() to reset gradients of model parameters.</li><li>Call loss.backward() to backpropagate gradients of prediction loss.</li><li>Call optimizer.step() to adjust model parameters.</li></ol></li></ul><h3 id="Step4-Train-amp-Test-amp-Pred"><a href="#Step4-Train-amp-Test-amp-Pred" class="headerlink" title="Step4 Train&Test&Pred"></a>Step4 Train&amp;Test&amp;Pred</h3><h4 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training setup</span></span><br><span class="line">dataset = MyDataset(file)       <span class="comment"># read data via MyDataset</span></span><br><span class="line">tr_set = DataLoader(dataset, <span class="number">16</span>, shuffle=<span class="literal">True</span>) <span class="comment"># put dataset into Dataloader</span></span><br><span class="line">model = MyModel().to(device)    <span class="comment"># construct model and move to device (cpu/cuda)</span></span><br><span class="line">criterion = nn.MSELoss()        <span class="comment"># set loss func</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), <span class="number">0.1</span>)    <span class="comment"># set optimizer</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Training Loop</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):   <span class="comment"># iterate n_epochs</span></span><br><span class="line">    model.tarin()               <span class="comment"># set model to train mode</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> tr_set:         <span class="comment"># iterate through the dataloader</span></span><br><span class="line">    optimizer.zero_grad()       <span class="comment"># set gradient to zero</span></span><br><span class="line">    x, y = x.to(device), y.to(device)   <span class="comment"># move data to device(cpu/cuda)</span></span><br><span class="line">    pred = model(x)             <span class="comment"># forward pass(compute output)</span></span><br><span class="line">    loss = criterion(pred, y)   <span class="comment"># compute loss</span></span><br><span class="line">    loss.backward()             <span class="comment"># computegradient(bp)</span></span><br><span class="line">    optimizer.step()            <span class="comment"># update model with optimizer</span></span><br></pre></td></tr></table></figure><h4 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                    <span class="comment"># set model to evaluation mode</span></span><br><span class="line">total_loss = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x, y <span class="keyword">in</span> dv_set:             <span class="comment"># iterate through the dataloader</span></span><br><span class="line">    x, y = x.to(device), y.to(device)   <span class="comment"># move data to device(cpu/cuda)</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():       <span class="comment"># disable gradient calculation</span></span><br><span class="line">        pred = model(x)         <span class="comment"># forward pass(compute output)</span></span><br><span class="line">        loss = criterion(pred, y)       <span class="comment"># compute loss</span></span><br><span class="line">    total_loss += loss.cpu().item() * <span class="built_in">len</span>() <span class="comment"># accumulate loss</span></span><br><span class="line">    avg_loss = total+loss / <span class="built_in">len</span>(dv_set.dataset) <span class="comment">#compute averaged loss</span></span><br></pre></td></tr></table></figure><h4 id="Predict"><a href="#Predict" class="headerlink" title="Predict"></a>Predict</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                    <span class="comment"># set model to evaluation mode</span></span><br><span class="line">preds = []:                     </span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> tt_set:                <span class="comment"># iterate through the dataloader </span></span><br><span class="line">    x = x.to(device)            <span class="comment"># move data to device</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():       <span class="comment"># disable gradient calculation</span></span><br><span class="line">        pred = model(x)         <span class="comment"># forward pass</span></span><br><span class="line">        preds.append(pred.cpu())    <span class="comment">#collect</span></span><br></pre></td></tr></table></figure><h2 id="Notice"><a href="#Notice" class="headerlink" title="Notice"></a>Notice</h2><h3 id="eval-amp-no-grad"><a href="#eval-amp-no-grad" class="headerlink" title="eval & no_grad"></a>eval &amp; no_grad</h3><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/62395e8e27f86abb2a0d56a2.jpg"></p><h3 id="load-amp-save"><a href="#load-amp-save" class="headerlink" title="load & save"></a>load &amp; save</h3><p><img lazyload="" alt="image" data-src="https://pic.imgdb.cn/item/62395ea727f86abb2a0df092.jpg"></p><h1 id="Tutorial2"><a href="#Tutorial2" class="headerlink" title="Tutorial2"></a>Tutorial2</h1><h2 id="load-data-x2F-Preprocessing"><a href="#load-data-x2F-Preprocessing" class="headerlink" title="load data/Preprocessing"></a>load data/Preprocessing</h2><p>Load data: you can use <strong>pandas</strong> to load a csv file.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data = pd.read_csv(<span class="string">"./covid.train.csv"</span>).drop(columns=[<span class="string">'date'</span>]).values</span><br></pre></td></tr></table></figure><p>Preprocessing: Get model inputs and labels.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_train, y_train = train_data[:,:-<span class="number">1</span>], train_data[:,-<span class="number">1</span>]  <span class="comment"># python的索引来说，右边】不包含</span></span><br></pre></td></tr></table></figure><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><ul><li><strong>init</strong>: Read data and preprocess</li><li><strong>getitem</strong>: Return one sample at a time. In this case, one sample includes a 117 dimensional feature and a label</li><li><strong>len</strong>: Return the size of the dataset. In this case, it is 2699</li></ul><h3 id="Dataloader"><a href="#Dataloader" class="headerlink" title="Dataloader"></a>Dataloader</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(train_dataset, ba)</span><br></pre></td></tr></table></figure><ul><li>Group data into batches</li><li>If you set <strong>shuffle = True</strong>, dataloader will permutes the indices of all samples automatically.</li><li>We often set <strong>shuffle = True</strong> during training</li><li>You can check this page <a class="link" target="_blank" rel="noopener" href="https://discuss.pytorch.org/t/advantage-to-shuffle-a-dataset/30584">Advantage to shuffle a dataset<i class="fas fa-external-link-alt"></i></a> if u are curious about why</li></ul><h2 id="Model-Building"><a href="#Model-Building" class="headerlink" title="Model Building"></a>Model Building</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">My_model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim</span>):</span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> modify model's structure, be aware of dimension.</span></span><br><span class="line">        self.layers = nn.Sequential(</span><br><span class="line">            nn.Linear(input_dim, <span class="number">64</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">32</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">32</span>, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    x = self.layers(x)</span><br><span class="line">    x = x.squeeze(<span class="number">1</span>) <span class="comment">#(B, 1) -&gt; B</span></span><br></pre></td></tr></table></figure><h2 id="Criterion"><a href="#Criterion" class="headerlink" title="Criterion"></a>Criterion</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用 Loss Func</span></span><br><span class="line">criterion = torch.nn.MSELoss(reduction = <span class="string">"mean"</span>)</span><br></pre></td></tr></table></figure><h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr = <span class="number">1e-5</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><h2 id="Training-loop"><a href="#Training-loop" class="headerlink" title="Training loop"></a>Training loop</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3000</span>):</span><br><span class="line">    model.train()   <span class="comment"># Set your model to train mode.</span></span><br><span class="line">    <span class="comment"># tqdm is a package to visualize your training progress.</span></span><br><span class="line">    train_pbar = tqdm(train_loader, position=<span class="number">0</span>, leave = <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> train_pbar:</span><br><span class="line">        x, y = x.to(<span class="string">'cuda'</span>), y.to(<span class="string">'cuda'</span>)   <span class="comment"># Move your data to device.</span></span><br><span class="line">        pred = model(x)</span><br><span class="line">        loss = criterion(pred, y)</span><br><span class="line">        loss.backward()                     <span class="comment"># Compute gradient</span></span><br><span class="line">        optimizer.step()                    <span class="comment"># Update parameters.</span></span><br><span class="line">        optimizer.zero_grad()               <span class="comment"># Set gradient to 0</span></span><br></pre></td></tr></table></figure></div><div class="post-copyright-info"><div class="article-copyright-info-container"><ul class="copyright-info-content"><li class="post-title"><span class="type">Post title</span>: <span class="content">PyTorch_Tutorial (TA Yuan Tseng)</span></li><li class="post-author"><span class="type">Post author</span>: <span class="content">Carpe Tu</span></li><li class="post-time"><span class="type">Create time</span>: <span class="content">2022-03-21 11:33:24</span></li><li class="post-link"><span class="type">Post link</span>: <span class="content">Tutorial/pytorch-tutorial-ta-yuan-tseng/</span></li><li class="post-license"><span class="type">Copyright notice</span>: <span class="content">All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.</span></li></ul><div class="copy-copyright-info flex-center tooltip" data-content="Copy copyright info" data-offset-y="-2px"><i class="fa-solid fa-copy"></i></div></div></div><ul class="post-tags-box"><li class="tag-item"><a href="/tags/Hung-yi-Lee/">#Hung-yi Lee</a>&nbsp;</li><li class="tag-item"><a href="/tags/PyTorch/">#PyTorch</a>&nbsp;</li></ul><div class="article-nav"><div class="article-prev"><a class="prev" rel="prev" href="/Tutorial/colab-tutorial/"><span class="left arrow-icon flex-center"><i class="fas fa-chevron-left"></i> </span><span class="title flex-center"><span class="post-nav-title-item">Colab_Tutorial</span> <span class="post-nav-item">Prev posts</span></span></a></div><div class="article-next"><a class="next" rel="next" href="/Funny-Stuff/meme-hung-yi-lee/"><span class="title flex-center"><span class="post-nav-title-item">MEME_Hung-yi Lee</span> <span class="post-nav-item">Next posts</span> </span><span class="right arrow-icon flex-center"><i class="fas fa-chevron-right"></i></span></a></div></div></div><div class="toc-content-container"><div class="post-toc-wrap"><div class="post-toc"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Videos-Link"><span class="nav-number">1.</span> <span class="nav-text">Videos Link</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Outline"><span class="nav-number">2.</span> <span class="nav-text">Outline</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Tutorial1"><span class="nav-number">3.</span> <span class="nav-text">Tutorial1</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Prerequisites"><span class="nav-number">3.1.</span> <span class="nav-text">Prerequisites</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PyTorch"><span class="nav-number">3.2.</span> <span class="nav-text">PyTorch</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Training-Neural-Networks"><span class="nav-number">3.2.1.</span> <span class="nav-text">Training Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Step1%E2%80%93Load-dataset"><span class="nav-number">3.2.2.</span> <span class="nav-text">Step1–Load dataset</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Dataset-amp-Dataloader"><span class="nav-number">3.2.2.1.</span> <span class="nav-text">Dataset &amp; Dataloader</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensor"><span class="nav-number">3.2.3.</span> <span class="nav-text">Tensor</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Tensor%E2%80%93Shape-of-Tensor"><span class="nav-number">3.2.3.1.</span> <span class="nav-text">Tensor–Shape of Tensor</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tensor%E2%80%93Creating-Tensors"><span class="nav-number">3.2.3.2.</span> <span class="nav-text">Tensor–Creating Tensors</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tensors%E2%80%93Comon-Operations"><span class="nav-number">3.2.3.3.</span> <span class="nav-text">Tensors–Comon Operations</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tensor%E2%80%93Data-Type"><span class="nav-number">3.2.3.4.</span> <span class="nav-text">Tensor–Data Type</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tensor%E2%80%93Device"><span class="nav-number">3.2.3.5.</span> <span class="nav-text">Tensor–Device</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tensors%E2%80%93Device-GPU"><span class="nav-number">3.2.3.6.</span> <span class="nav-text">Tensors–Device(GPU)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tensors%E2%80%93Gradient-Calculation"><span class="nav-number">3.2.3.7.</span> <span class="nav-text">Tensors–Gradient Calculation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Step2%E2%80%93Build-NN"><span class="nav-number">3.2.4.</span> <span class="nav-text">Step2–Build NN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#torch-nn%E2%80%93Network-Layers"><span class="nav-number">3.2.4.1.</span> <span class="nav-text">torch.nn–Network Layers</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#torch-nn-%E2%80%93-Non-Linear-Activation-Function"><span class="nav-number">3.2.4.2.</span> <span class="nav-text">torch.nn – Non-Linear Activation Function</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#torch-nn-%E2%80%93-Build-Neural-Network"><span class="nav-number">3.2.4.3.</span> <span class="nav-text">torch.nn – Build Neural Network</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Step3%E2%80%93Loss-Func-amp-Optim"><span class="nav-number">3.2.5.</span> <span class="nav-text">Step3–Loss Func &amp; Optim</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#torch-nn%E2%80%93Loss-Functions"><span class="nav-number">3.2.5.1.</span> <span class="nav-text">torch.nn–Loss Functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#torch-optim"><span class="nav-number">3.2.5.2.</span> <span class="nav-text">torch.optim</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Step4-Train-amp-Test-amp-Pred"><span class="nav-number">3.2.6.</span> <span class="nav-text">Step4 Train&amp;Test&amp;Pred</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Train"><span class="nav-number">3.2.6.1.</span> <span class="nav-text">Train</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Test"><span class="nav-number">3.2.6.2.</span> <span class="nav-text">Test</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Predict"><span class="nav-number">3.2.6.3.</span> <span class="nav-text">Predict</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Notice"><span class="nav-number">3.3.</span> <span class="nav-text">Notice</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#eval-amp-no-grad"><span class="nav-number">3.3.1.</span> <span class="nav-text">eval &amp; no_grad</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#load-amp-save"><span class="nav-number">3.3.2.</span> <span class="nav-text">load &amp; save</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Tutorial2"><span class="nav-number">4.</span> <span class="nav-text">Tutorial2</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#load-data-x2F-Preprocessing"><span class="nav-number">4.1.</span> <span class="nav-text">load data&#x2F;Preprocessing</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Dataset"><span class="nav-number">4.1.1.</span> <span class="nav-text">Dataset</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dataloader"><span class="nav-number">4.1.2.</span> <span class="nav-text">Dataloader</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Model-Building"><span class="nav-number">4.2.</span> <span class="nav-text">Model Building</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Criterion"><span class="nav-number">4.3.</span> <span class="nav-text">Criterion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Optimizer"><span class="nav-number">4.4.</span> <span class="nav-text">Optimizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Training-loop"><span class="nav-number">4.5.</span> <span class="nav-text">Training loop</span></a></li></ol></li></ol></div></div></div></div></div></div></div><div class="page-main-content-bottom"><footer class="footer"><div class="info-container"><div class="copyright-info info-item">&copy; <span>2021</span> - 2023 &nbsp;<i class="fas fa-heart icon-animate"></i> &nbsp;<a href="/">Carpe Tu</a></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="website-count info-item">Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp; Totalview&nbsp;<span id="busuanzi_value_site_pv"></span></div><div class="theme-info info-item">Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.6.1</a></div></div></footer></div></div><div class="post-tools"><div class="post-tools-container"><ul class="tools-list"><li class="tools-item flex-center toggle-show-toc"><i class="fas fa-list"></i></li></ul></div></div><div class="right-bottom-side-tools"><div class="side-tools-container"><ul class="side-tools-list"><li class="tools-item tool-font-adjust-plus flex-center"><i class="fas fa-search-plus"></i></li><li class="tools-item tool-font-adjust-minus flex-center"><i class="fas fa-search-minus"></i></li><li class="tools-item tool-dark-light-toggle flex-center"><i class="fas fa-moon"></i></li><li class="tools-item rss flex-center"><a class="flex-center" href="/atom.xml" target="_blank"><i class="fas fa-rss"></i></a></li><li class="tools-item tool-scroll-to-bottom flex-center"><i class="fas fa-arrow-down"></i></li></ul><ul class="exposed-tools-list"><li class="tools-item tool-toggle-show flex-center"><i class="fas fa-cog fa-spin"></i></li><li class="tools-item tool-scroll-to-top flex-center"><i class="arrow-up fas fa-arrow-up"></i> <span class="percent"></span></li></ul></div></div><div class="zoom-in-image-mask"><img class="zoom-in-image"></div><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-input-field-pre"><i class="fas fa-keyboard"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="Search..." spellcheck="false" type="search" class="search-input"></div><span class="close-popup-btn"><i class="fas fa-times"></i></span></div><div id="search-result"><div id="no-result"><i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></main><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/dark-light-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/local-search.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/code-block.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/lazyload.js"></script><div class="post-scripts pjax"><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/post-helper.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/toc.js"></script></div><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/libs/pjax.min.js"></script><script>window.addEventListener("DOMContentLoaded",()=>{window.pjax=new Pjax({selectors:["head title",".page-container",".pjax"],history:!0,debug:!1,cacheBust:!1,timeout:0,analytics:!1,currentUrlFullReload:!1,scrollRestoration:!1}),document.addEventListener("pjax:send",()=>{KEEP.utils.pjaxProgressBarStart()}),document.addEventListener("pjax:complete",()=>{KEEP.utils.pjaxProgressBarEnd(),window.pjax.executeScripts(document.querySelectorAll("script[data-pjax], .pjax script")),KEEP.refresh()})})</script></body></html>